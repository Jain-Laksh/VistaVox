{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d966600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "407a058e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laksh.jain/laksh_3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7306c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"../image_story_description/image_story_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da62ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = split_dataset['train']\n",
    "eval_dataset = split_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a29800",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a poetic and vivid storyteller guiding a blind person through what the camera sees. \n",
    "Describe the images like a flowing story, using rich adjectives, sensory details, and present continuous tense. Avoid guessing.\"\"\"\n",
    "\n",
    "prompt = \"\"\"Describe the image vividly in present continuous tense, using rich adjectives and sensory details. Write like a story.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e75ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(sample):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": system_message}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": sample[\"image\"],\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt,\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": sample[\"description\"]}],\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76fdc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_formatted = [format_data(sample) for sample in train_dataset]\n",
    "eval_dataset_formatted = [format_data(sample) for sample in eval_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "951ca94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'You are a poetic and vivid storyteller guiding a blind person through what the camera sees. \\nDescribe the images like a flowing story, using rich adjectives, sensory details, and present continuous tense. Avoid guessing.'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'image',\n",
       "    'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x333>},\n",
       "   {'type': 'text',\n",
       "    'text': 'Describe the image vividly in present continuous tense, using rich adjectives and sensory details. Write like a story.'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'A beautiful woman holding a tennis racquet stands on a tennis court, her eyes fixed on the ball in flight. She swings the racquet with precision, aiming to send the ball back to the opponent. The court is alive with the sound of the ball hitting the strings and the rhythmic motion of her feet. The woman in a white outfit moves fluidly across the court, determined to win the point.'}]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset_formatted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6d2b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"HuggingFaceTB/SmolVLM-500M-Instruct\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "base_model = AutoModelForVision2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=DEVICE,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    _attn_implementation=\"eager\",\n",
    ").to(DEVICE)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "870c6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_from_sample(model, processor, sample, max_new_tokens=200, DEVICE=\"cuda\"):\n",
    "\n",
    "    # Prepare inputs\n",
    "    prompt = processor.apply_chat_template(sample[0:2], add_generation_prompt=True) # passing the prompt without the system message or the assistant's response\n",
    "    \n",
    "    image = sample[1]['content'][0]['image']\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "    inputs = processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
    "    inputs = inputs.to(DEVICE)\n",
    "\n",
    "    # Generate text with the model\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    # Trim the generated ids to remove the input ids\n",
    "    trimmed_generated_ids = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
    "\n",
    "    # Decode the output text\n",
    "    output_text = processor.batch_decode(\n",
    "        trimmed_generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return output_text[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fbcd017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a csv file\n",
    "import csv\n",
    "csv_file_path = \"base_model_response.csv\"\n",
    "csv_file = open(csv_file_path, mode=\"w\", newline=\"\", encoding=\"utf-8\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"image\", \"description\", \"model_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6c146ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating model outputs: 100%|██████████| 150/150 [13:12<00:00,  5.28s/it]\n"
     ]
    }
   ],
   "source": [
    "for sample in tqdm(eval_dataset_formatted, total=len(eval_dataset_formatted), desc=\"Generating model outputs\"):\n",
    "    image = sample[1]['content'][0]['image']\n",
    "    description = sample[2]['content'][0]['text']\n",
    "    model_output = generate_text_from_sample(base_model, processor, sample, max_new_tokens=200, DEVICE=DEVICE)  \n",
    "    csv_writer.writerow([image, description, model_output])\n",
    "    \n",
    "csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laksh_3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
